#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os, sys, re
import codecs
from itertools import chain
import lxml.etree, lxml.html

import openlawDb

# Configuration
base_url = "http://www.gesetze-im-internet.de/"

# Open db connection
db = openlawDb.connect_db()

# Delete old entries
openlawDb.init_db()

# Root node
root_alphabet = lxml.html.parse(base_url+"aktuell.html").getroot()

# Get list of all laws
# (name, fulltitle, slug/link)
def getAllLaws():
    ret = []

    alphabet = root_alphabet.cssselect("#container .alphabet")
    for el in alphabet:
        if el.attrib.has_key('href'):
            alphabet_elem = lxml.html.parse(base_url+el.attrib['href']).getroot()

            link_elem = alphabet_elem.cssselect("#paddingLR12 p a")
            title_elem = alphabet_elem.cssselect("#paddingLR12 p a abbr")

            for (el_link, el_title) in zip(link_elem, title_elem):
                if el_link.attrib.has_key('href') and not el_link.attrib['href'].endswith('.pdf'):
                    ret.append((
                            re.escape(el_title.text.lstrip(' ').rstrip(' ')),
                            re.escape(el_title.attrib['title']),
                            el_link.attrib['href'][2:-11]
                        ))
    return ret


# Get headline + text for specific law
def getLawText(slug, html):
    # Fix: for laws without headlines

    # Initialize helper variables
    fakeLinkIDs = []
    i = 0
    first = True

    # Return variables
    lawHeads = []
    lawTexts = []

    trs = html.xpath("//div[@id='paddingLR12']/table/tr")
    if len(trs) == 0:
        trs = html.xpath("//div[@id='paddingLR12']")

    for tr in trs:
        i = i+1

        tds = tr.xpath("child::td")
        if len(tds) == 0:
            text = ""
        else:
            text = tr.xpath("child::td/descendant::text()")[-1]

        # Skip if headline text is empty, unless its the first entry
        tmp_text = text.replace(u' ', u'').replace(u'\xa0', u'')
        if not first and tmp_text is "":
            continue

        ###
        # HEADLINE
        ###
        depth = 0
        if len(tds) == 0:
            head_link = tr.xpath("child::table/a/attribute::href")[0]
            head_root = lxml.html.parse(base_url+slug+"/"+head_link).getroot()
        else:
            depth = len(tds)
            if len(tds) < 3:
                colspan = tds[-1].xpath("attribute::colspan")[0]
                depth = 4 - int(colspan)

            if first:
                if text[0] != u"ยง" and not text.startswith("Art"):
                    depth = 1


            head_link = tds[-1].xpath("child::a/attribute::href")[0]
            head_root = lxml.html.parse(base_url+slug+"/"+head_link).getroot()

        # Append headline
        if '#' in head_link and not first:
            lawHeads.append((-depth, text))
        else:
            lawHeads.append((depth, text))

        ###
        # TEXT
        ###

        # Its only a link to the whole law text rather to one part of it
        if '#' in head_link and not first:
            fakeLinkIDs.append(i)
            continue

        # Cleaning
        for bad in head_root.xpath("//a[text()='Nichtamtliches Inhaltsverzeichnis']"):
            bad.getparent().remove(bad)
        for bad in head_root.xpath("//div[contains(@class, 'jnheader')]"):
            bad.getparent().remove(bad)
        for tag in head_root.xpath('//*[@class]'):
            # For each element with a class attribute, remove that class attribute
            tag.attrib.pop('class')


        headHtml_elem = head_root.cssselect("#paddingLR12")


        # Write "link" to real first chapters
        if len(fakeLinkIDs) != 0:
            for fake in fakeLinkIDs:
                lawTexts.append("%%%i%%" % i)
            fakeLinkIDs = []
        else:
            # Write text
            lawTexts.append(lxml.etree.tostring(headHtml_elem[0]))

        if first:
            first = False

    return lawHeads, lawTexts


if __name__ == '__main__':
    # First, fetch links to all laws + short name and full name
    laws = getAllLaws()

    # Iter throu' all laws
    i = 1
    lawIter = chain(laws);
    while True:
        try:
            name, title, slug = lawIter.next()
        except StopIteration:
            # TODO
            break

        # Add laws
        db.execute('insert into Laws (slug, short_name, long_name) values (?, ?, ?)',
             [slug, name, title])
        db.commit()

        print "Insert: %s" % slug

        # Get headlines and law text
        law_index_html = lxml.html.parse(base_url+slug+"/index.html").getroot()
        heads, texts = getLawText(slug, law_index_html)
        i = 0;
        for head, text in zip(heads, texts):
            db.execute('insert into Law_Heads (id, law_id, depth, headline) values \
              (?, (select id from Laws where slug = "%s"), ?, ?)' % slug,
             [i, head[0], head[1]])

            i += 1;
     

    # Flush database
    db.commit()
exit()


with codecs.open(output_dir + "/laws", 'w', 'utf-8') as lawsFile:
    lawsFile.write("[\n")

    while True:
        try:
            name,title,slug = lawIter.next()
        except StopIteration:
            lawsFile.write(u'["%s", "%s", "%s"]\n]' % ( name,slug,title ))
            break

        print "Loading #%i: %s" % (i, name)

        lawsFile.write(u'["%s", "%s", "%s"],\n' % ( name,slug,title ))

        law_index_html = lxml.html.parse(base_url+slug+"/index.html").getroot()
        for head, text in zip(writeLawText(slug, law_index_html)):
            print head

        i = i+1

if db is not None:
    db.close()

    